{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOPIC -Chest XRAY Image Classification in normal, covid, Tuberculosis and Pneumonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_dir = 'C:\\Users\\Muleh\\OneDrive\\Desktop\\om summer\\CODE.ipynb'\n",
    "test_path = my_data_dir+'/test/'\n",
    "train_path = my_data_dir+'/train/'\n",
    "val_path = my_data_dir+'/val/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "path = 'C:\\Users\\Muleh\\OneDrive\\Desktop\\om summer\\CODE.ipynb/train/'\n",
    "file_path = os.listdir(path)\n",
    "\n",
    "for i in file_path:\n",
    "    path_final = 'C:\\Users\\Muleh\\OneDrive\\Desktop\\om summer\\CODE.ipynb/train/' + i + '/'\n",
    "    final = os.listdir(path_final)\n",
    "    for j in final:\n",
    "        data = path_final + j\n",
    "        img = cv2.imread(data)\n",
    "        image = cv2.resize(img, (224,224))\n",
    "        cv2.imwrite(data,image)\n",
    "#         print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "path = 'C:\\Users\\Muleh\\OneDrive\\Desktop\\om summer\\CODE.ipynb/val/'\n",
    "file_path = os.listdir(path)\n",
    "\n",
    "for i in file_path:\n",
    "    path_final = 'C:\\Users\\Muleh\\OneDrive\\Desktop\\om summer\\CODE.ipynb/val/' + i + '/'\n",
    "    final = os.listdir(path_final)\n",
    "    for j in final:\n",
    "        data = path_final + j\n",
    "        img = cv2.imread(data)\n",
    "        image = cv2.resize(img, (224,224))\n",
    "        cv2.imwrite(data,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "path = 'C:\\Users\\Muleh\\OneDrive\\Desktop\\om summer\\CODE.ipynb/test/'\n",
    "file_path = os.listdir(path)\n",
    "\n",
    "for i in file_path:\n",
    "    path_final = 'C:\\Users\\Muleh\\OneDrive\\Desktop\\om summer\\CODE.ipynb/test/' + i + '/'\n",
    "    final = os.listdir(path_final)\n",
    "    for j in final:\n",
    "        data = path_final + j\n",
    "        img = cv2.imread(data)\n",
    "        image = cv2.resize(img, (224,224))\n",
    "        cv2.imwrite(data,image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we are using the image data generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (224,224)\n",
    "image_gen = ImageDataGenerator(rotation_range=20,\n",
    "                               width_shift_range=0.10,\n",
    "                               height_shift_range=0.10,\n",
    "                               rescale=1/255,\n",
    "                               shear_range=0.1,\n",
    "                               zoom_range=0.1,\n",
    "                               horizontal_flip=True,\n",
    "                               fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a convolutional neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6326 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_image_gen = image_gen.flow_from_directory(train_path,\n",
    "                                               target_size= (224,224),\n",
    "                                                \n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "val_image_gen = image_gen.flow_from_directory(val_path,\n",
    "                                               target_size= (224,224),\n",
    "                                              \n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical',shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 771 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_image_gen = image_gen.flow_from_directory(test_path,\n",
    "                                               target_size= (224,224),\n",
    "                                              \n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical',shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'COVID19': 0, 'NORMAL': 1, 'PNEUMONIA': 2, 'TURBERCULOSIS': 3}\n",
      "{'COVID19': 0, 'NORMAL': 1, 'PNEUMONIA': 2, 'TURBERCULOSIS': 3}\n"
     ]
    }
   ],
   "source": [
    "print(train_image_gen.class_indices)\n",
    "Labels=train_image_gen.class_indices\n",
    "print(val_image_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 224, 224, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_gen[1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape = (224,224, 3), include_top = False, weights = \"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([base_model,\n",
    "                                 tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                             tf.keras.layers.Dense(4096, activation=\"relu\"),\n",
    "                             tf.keras.layers.Dense(2048, activation=\"relu\"),\n",
    "                                 tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
    "                             tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "                             tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "                             \n",
    "                             tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "                                 tf.keras.layers.Dense(4, activation=\"softmax\")                                     \n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 58s 537ms/step - loss: 0.1984 - accuracy: 0.8419 - val_loss: 0.3735 - val_accuracy: 0.6579\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 51s 507ms/step - loss: 0.1133 - accuracy: 0.9162 - val_loss: 0.3021 - val_accuracy: 0.7368\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 48s 480ms/step - loss: 0.0876 - accuracy: 0.9350 - val_loss: 0.2013 - val_accuracy: 0.8158\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 50s 496ms/step - loss: 0.0872 - accuracy: 0.9344 - val_loss: 0.1881 - val_accuracy: 0.7895\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 0.0881 - accuracy: 0.9308 - val_loss: 0.2617 - val_accuracy: 0.7368\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 49s 493ms/step - loss: 0.0659 - accuracy: 0.9463 - val_loss: 0.1622 - val_accuracy: 0.8684\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 49s 485ms/step - loss: 0.0689 - accuracy: 0.9538 - val_loss: 0.2641 - val_accuracy: 0.7895\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 51s 507ms/step - loss: 0.0795 - accuracy: 0.9365 - val_loss: 0.3352 - val_accuracy: 0.7105\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 50s 501ms/step - loss: 0.0661 - accuracy: 0.9444 - val_loss: 0.3284 - val_accuracy: 0.7632\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 52s 519ms/step - loss: 0.0631 - accuracy: 0.9541 - val_loss: 0.1721 - val_accuracy: 0.8684\n"
     ]
    }
   ],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_image_gen, validation_data = val_image_gen, steps_per_epoch = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 25s 488ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 2, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 1, 2,\n",
       "       1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2,\n",
       "       2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(test_image_gen), axis = -1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93       106\n",
      "           1       0.91      0.68      0.78       234\n",
      "           2       0.82      0.97      0.89       390\n",
      "           3       0.97      0.95      0.96        41\n",
      "\n",
      "    accuracy                           0.87       771\n",
      "   macro avg       0.93      0.87      0.89       771\n",
      "weighted avg       0.88      0.87      0.87       771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(test_image_gen.classes,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93   3   9   1]\n",
      " [  0 159  75   0]\n",
      " [  0  11 379   0]\n",
      " [  0   1   1  39]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_image_gen.classes,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 10s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionV3(input_shape = (224, 224, 3), include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = tf.keras.layers.Flatten()(base_model.output)\n",
    "x = tf.keras.layers.Dense(2048, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "x = tf.keras.layers.Dense(4, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 204s 2s/step - loss: 0.5362 - acc: 0.7019 - val_loss: 0.3642 - val_acc: 0.6842\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 189s 2s/step - loss: 0.2118 - acc: 0.8333 - val_loss: 0.4230 - val_acc: 0.6316\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 187s 2s/step - loss: 0.1679 - acc: 0.8667 - val_loss: 0.3151 - val_acc: 0.7368\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 195s 2s/step - loss: 0.1680 - acc: 0.8650 - val_loss: 0.4791 - val_acc: 0.6842\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 186s 2s/step - loss: 0.1374 - acc: 0.8981 - val_loss: 0.5458 - val_acc: 0.6842\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 188s 2s/step - loss: 0.1397 - acc: 0.9000 - val_loss: 0.2605 - val_acc: 0.8158\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 190s 2s/step - loss: 0.1231 - acc: 0.9031 - val_loss: 0.6939 - val_acc: 0.7632\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 197s 2s/step - loss: 0.1076 - acc: 0.9225 - val_loss: 0.5775 - val_acc: 0.7632\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 200s 2s/step - loss: 0.1150 - acc: 0.9162 - val_loss: 0.6016 - val_acc: 0.7105\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 220s 2s/step - loss: 0.1096 - acc: 0.9169 - val_loss: 0.4879 - val_acc: 0.8158\n"
     ]
    }
   ],
   "source": [
    "inc_history = model.fit_generator(train_image_gen, validation_data = val_image_gen, steps_per_epoch = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 59s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 3, 3, 3, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 3,\n",
       "       0, 0, 0, 2, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0,\n",
       "       3, 3, 0, 0, 3, 3, 3, 2, 0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 3, 3, 2, 2, 3, 0, 3, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 1, 3, 2, 2, 2, 2, 3, 2, 2, 2, 0, 2, 2, 1, 2, 1, 3,\n",
       "       2, 1, 0, 0, 2, 3, 3, 3, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 3,\n",
       "       2, 2, 3, 2, 2, 3, 2, 3, 1, 2, 1, 1, 1, 3, 1, 3, 2, 1, 2, 3, 1, 2,\n",
       "       3, 2, 2, 2, 2, 3, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 3, 2, 1, 1, 3,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 1, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n",
       "       2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 3, 2, 1, 2, 1, 2, 2, 1, 2, 2,\n",
       "       2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(test_image_gen), axis = -1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.80       106\n",
      "           1       0.98      0.26      0.41       234\n",
      "           2       0.71      0.99      0.83       390\n",
      "           3       0.46      1.00      0.63        41\n",
      "\n",
      "    accuracy                           0.73       771\n",
      "   macro avg       0.78      0.73      0.67       771\n",
      "weighted avg       0.82      0.73      0.69       771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(test_image_gen.classes,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73   0   5  28]\n",
      " [  3  60 151  20]\n",
      " [  0   1 388   1]\n",
      " [  0   0   0  41]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_image_gen.classes,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
    "include_top = False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "from tensorflow.keras import layers \n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(2048, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# Add a final sigmoid layer with 102 node for classification output\n",
    "x = layers.Dense(102, activation='relu')(x)\n",
    "x = layers.Dense(4, activation='sigmoid')(x)\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'BinaryCrossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 460s 5s/step - loss: 0.3259 - acc: 0.7212 - val_loss: 0.8143 - val_acc: 0.4737\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 477s 5s/step - loss: 0.1914 - acc: 0.8450 - val_loss: 0.4277 - val_acc: 0.6842\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 453s 5s/step - loss: 0.1414 - acc: 0.8806 - val_loss: 0.1840 - val_acc: 0.8421\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 383s 4s/step - loss: 0.1339 - acc: 0.9019 - val_loss: 0.1785 - val_acc: 0.8421\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 375s 4s/step - loss: 0.1279 - acc: 0.9025 - val_loss: 0.2696 - val_acc: 0.7895\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 398s 4s/step - loss: 0.0962 - acc: 0.9319 - val_loss: 0.3948 - val_acc: 0.7105\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 399s 4s/step - loss: 0.1131 - acc: 0.9239 - val_loss: 0.4698 - val_acc: 0.7105\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 413s 4s/step - loss: 0.1110 - acc: 0.9187 - val_loss: 0.2061 - val_acc: 0.8158\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 7386s 75s/step - loss: 0.1003 - acc: 0.9289 - val_loss: 0.3106 - val_acc: 0.8421\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 358s 4s/step - loss: 0.1115 - acc: 0.9277 - val_loss: 0.1417 - val_acc: 0.8684\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit_generator(train_image_gen, validation_data = val_image_gen, steps_per_epoch = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 153s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0,\n",
       "       0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 3,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "       1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1,\n",
       "       2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(test_image_gen), axis = -1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89       106\n",
      "           1       0.91      0.77      0.84       234\n",
      "           2       0.88      0.96      0.92       390\n",
      "           3       0.69      1.00      0.82        41\n",
      "\n",
      "    accuracy                           0.89       771\n",
      "   macro avg       0.87      0.89      0.87       771\n",
      "weighted avg       0.89      0.89      0.89       771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(test_image_gen.classes,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 87   4   2  13]\n",
      " [  1 181  47   5]\n",
      " [  1  14 375   0]\n",
      " [  0   0   0  41]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_image_gen.classes,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "model = Sequential()\n",
    "\n",
    "model.add(ResNet50(include_top=False, pooling='avg'))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'BinaryCrossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 167s 2s/step - loss: 0.6167 - acc: 0.6506 - val_loss: 0.5748 - val_acc: 0.3158\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 140s 1s/step - loss: 0.4693 - acc: 0.7767 - val_loss: 0.5509 - val_acc: 0.3684\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 137s 1s/step - loss: 0.4068 - acc: 0.7987 - val_loss: 0.5211 - val_acc: 0.4737\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 143s 1s/step - loss: 0.3632 - acc: 0.8081 - val_loss: 0.5249 - val_acc: 0.4211\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 163s 2s/step - loss: 0.3340 - acc: 0.8194 - val_loss: 0.4971 - val_acc: 0.4737\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 162s 2s/step - loss: 0.3086 - acc: 0.8062 - val_loss: 0.4046 - val_acc: 0.5526\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 169s 2s/step - loss: 0.2724 - acc: 0.8313 - val_loss: 0.4114 - val_acc: 0.6316\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 167s 2s/step - loss: 0.2421 - acc: 0.8453 - val_loss: 0.3876 - val_acc: 0.7368\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 169s 2s/step - loss: 0.2243 - acc: 0.8575 - val_loss: 0.3969 - val_acc: 0.6842\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 162s 2s/step - loss: 0.2130 - acc: 0.8575 - val_loss: 0.2876 - val_acc: 0.8158\n"
     ]
    }
   ],
   "source": [
    "resnet = model.fit_generator(train_image_gen, validation_data = val_image_gen, steps_per_epoch = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 76s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 2,\n",
       "       0, 3, 0, 0, 3, 0, 2, 0, 3, 2, 0, 0, 0, 0, 0, 3, 0, 3, 2, 0, 2, 2,\n",
       "       0, 0, 3, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 2, 2, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 2, 1, 0, 2, 0, 2, 1, 0, 0, 2, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1,\n",
       "       1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2,\n",
       "       1, 1, 2, 0, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2,\n",
       "       1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 1, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1,\n",
       "       1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1,\n",
       "       2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 2, 1, 2, 2,\n",
       "       2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 3, 3, 1, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(test_image_gen), axis = -1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.79       106\n",
      "           1       0.90      0.55      0.68       234\n",
      "           2       0.77      0.97      0.86       390\n",
      "           3       0.71      0.83      0.76        41\n",
      "\n",
      "    accuracy                           0.80       771\n",
      "   macro avg       0.81      0.77      0.77       771\n",
      "weighted avg       0.82      0.80      0.79       771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(test_image_gen.classes,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 79   1  12  14]\n",
      " [ 13 128  93   0]\n",
      " [  1  12 377   0]\n",
      " [  0   2   5  34]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_image_gen.classes,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
